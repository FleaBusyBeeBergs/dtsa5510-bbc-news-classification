{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22cf2177-3108-44ca-8960-ba364798712c",
   "metadata": {},
   "source": [
    "# Week 4: BBC News Classification Project\n",
    "## DTSA 5510 - Intro to Machine Learning - Unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c1d3469-036b-4067-993e-49ae664e1a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74ee3b9a-5b3b-4c62-838c-0395b7539531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloads required to make this notebook run\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "# nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d00fdcf9-4c36-4b5e-89ad-2be5ac56a59a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1833</td>\n",
       "      <td>worldcom ex-boss launches defence lawyers defe...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154</td>\n",
       "      <td>german business confidence slides german busin...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1101</td>\n",
       "      <td>bbc poll indicates economic gloom citizens in ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1976</td>\n",
       "      <td>lifestyle  governs mobile choice  faster  bett...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>917</td>\n",
       "      <td>enron bosses in $168m payout eighteen former e...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ArticleId                                               Text  Category\n",
       "0       1833  worldcom ex-boss launches defence lawyers defe...  business\n",
       "1        154  german business confidence slides german busin...  business\n",
       "2       1101  bbc poll indicates economic gloom citizens in ...  business\n",
       "3       1976  lifestyle  governs mobile choice  faster  bett...      tech\n",
       "4        917  enron bosses in $168m payout eighteen former e...  business"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data\n",
    "train_df = pd.read_csv('data/BBC News Train.csv')\n",
    "\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d623ee-694b-4d35-95d4-74cca6875478",
   "metadata": {},
   "source": [
    "### EDA & cleaning:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5e4a57-b545-4ef7-bc46-5be6f8f5f19c",
   "metadata": {},
   "source": [
    "Make pipleline to preprocess data\n",
    "* remove missing text (none in this data)\n",
    "* remove duplicate text\n",
    "* tokenize text\n",
    "* tfidf_vectorizer, plot scores\n",
    "\n",
    "Make pipeline to Modeling\n",
    "* non-negative matrix factorization models\n",
    "    * Frobenius Loss\n",
    "    * Kullback-Leibler Divergence \n",
    "    * plot top words per topic\n",
    "* Compare to supervised learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c463c00d-8e4a-4085-81da-7f62998edfe6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1490 entries, 0 to 1489\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   ArticleId  1490 non-null   int64 \n",
      " 1   Text       1490 non-null   object\n",
      " 2   Category   1490 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 35.1+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d429c0-69db-48d6-981f-93829176a661",
   "metadata": {},
   "source": [
    "There are no missing values in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dfc05e0-60b3-43b2-9425-84aa3da117d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove duplicates\n",
    "def remove_duplicates(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # number of duplicates\n",
    "    number_duplicates = df['Text'].duplicated().sum()\n",
    "\n",
    "    # print no. duplicates\n",
    "    print(f'No. of duplicate articles: {number_duplicates}' '\\n')\n",
    "\n",
    "    # removal\n",
    "    df_cleaned = df.drop_duplicates(subset = ['Text'])\n",
    "\n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bebf5986-96b4-441c-9797-797e10209aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of duplicate articles: 50\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1833</td>\n",
       "      <td>worldcom ex-boss launches defence lawyers defe...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154</td>\n",
       "      <td>german business confidence slides german busin...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1101</td>\n",
       "      <td>bbc poll indicates economic gloom citizens in ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1976</td>\n",
       "      <td>lifestyle  governs mobile choice  faster  bett...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>917</td>\n",
       "      <td>enron bosses in $168m payout eighteen former e...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>857</td>\n",
       "      <td>double eviction from big brother model caprice...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>325</td>\n",
       "      <td>dj double act revamp chart show dj duo jk and ...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>1590</td>\n",
       "      <td>weak dollar hits reuters revenues at media gro...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488</th>\n",
       "      <td>1587</td>\n",
       "      <td>apple ipod family expands market apple has exp...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>538</td>\n",
       "      <td>santy worm makes unwelcome visit thousands of ...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1440 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ArticleId                                               Text  \\\n",
       "0          1833  worldcom ex-boss launches defence lawyers defe...   \n",
       "1           154  german business confidence slides german busin...   \n",
       "2          1101  bbc poll indicates economic gloom citizens in ...   \n",
       "3          1976  lifestyle  governs mobile choice  faster  bett...   \n",
       "4           917  enron bosses in $168m payout eighteen former e...   \n",
       "...         ...                                                ...   \n",
       "1485        857  double eviction from big brother model caprice...   \n",
       "1486        325  dj double act revamp chart show dj duo jk and ...   \n",
       "1487       1590  weak dollar hits reuters revenues at media gro...   \n",
       "1488       1587  apple ipod family expands market apple has exp...   \n",
       "1489        538  santy worm makes unwelcome visit thousands of ...   \n",
       "\n",
       "           Category  \n",
       "0          business  \n",
       "1          business  \n",
       "2          business  \n",
       "3              tech  \n",
       "4          business  \n",
       "...             ...  \n",
       "1485  entertainment  \n",
       "1486  entertainment  \n",
       "1487       business  \n",
       "1488           tech  \n",
       "1489           tech  \n",
       "\n",
       "[1440 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = remove_duplicates(train_df)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de4c7d9-b954-425f-8f6a-54d16cbd778c",
   "metadata": {},
   "source": [
    "### Data transformers:\n",
    "\n",
    "A uniform method is needed to preprocess the text in both the training and the testing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "544c4c06-5602-4733-8121-94e1ac7a1417",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    def preprocess_text(self,text):\n",
    "        # tokenize\n",
    "        tokens = word_tokenize(text)\n",
    "\n",
    "        # remove stop words\n",
    "        tokens = [word for word in tokens if word.lower() not in self.stop_words]\n",
    "\n",
    "        # lower case\n",
    "        tokens = [word.lower() for word in tokens]\n",
    "\n",
    "        # lemmatization\n",
    "        tokens = [self.lemmatizer.lemmatize(word) for word in tokens]\n",
    "        \n",
    "        # remove punctuation\n",
    "        tokens = [word for word in tokens if word.isalpha()]\n",
    "\n",
    "        # join tokens\n",
    "        return ' '.join(tokens)\n",
    "\n",
    "    # fit to data\n",
    "    def fit_text(self, X, y = None):\n",
    "        return self\n",
    "        \n",
    "    # transform\n",
    "    def transform_text(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X_copy = X.copy()\n",
    "            X_copy['Text'] = X_copy['Text'].apply(self. preprocess_text)\n",
    "            return X_copy\n",
    "        else:    \n",
    "            raise ValueError('''Input should be data frame with a column named 'Text' ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562da6a0-8d49-4fed-ac00-15283cb2892b",
   "metadata": {},
   "source": [
    "### Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7863799-e2d7-4d3e-a0d5-20b2e6053b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define custom transformer\n",
    "text_preprocessor = TextPreprocessor()\n",
    "\n",
    "text_preprocessor.fit_text(train_df)\n",
    "\n",
    "train_df = text_preprocessor.transform_text(train_df) \n",
    "\n",
    "# define pre-processor pipeline\n",
    "# pipeline = Pipeline(steps=[\n",
    "#  #    \n",
    "#     ('preprocessor', ColumnTransformer(\n",
    "#         transformers=[\n",
    "#             ('text_preprocessing', text_preprocessor, 'Text')\n",
    "#         ],\n",
    "#         remainder='passthrough'  \n",
    "#     ))\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b0d3635-8dcb-40c8-8d4a-171e717f361f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1833</td>\n",
       "      <td>worldcom launch defence lawyer defending forme...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154</td>\n",
       "      <td>german business confidence slide german busine...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1101</td>\n",
       "      <td>bbc poll indicates economic gloom citizen majo...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1976</td>\n",
       "      <td>lifestyle governs mobile choice faster better ...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>917</td>\n",
       "      <td>enron boss payout eighteen former enron direct...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>857</td>\n",
       "      <td>double eviction big brother model caprice holb...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>325</td>\n",
       "      <td>dj double act revamp chart show dj duo jk joel...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>1590</td>\n",
       "      <td>weak dollar hit reuters revenue medium group r...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488</th>\n",
       "      <td>1587</td>\n",
       "      <td>apple ipod family expands market apple expande...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>538</td>\n",
       "      <td>santy worm make unwelcome visit thousand websi...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1440 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ArticleId                                               Text  \\\n",
       "0          1833  worldcom launch defence lawyer defending forme...   \n",
       "1           154  german business confidence slide german busine...   \n",
       "2          1101  bbc poll indicates economic gloom citizen majo...   \n",
       "3          1976  lifestyle governs mobile choice faster better ...   \n",
       "4           917  enron boss payout eighteen former enron direct...   \n",
       "...         ...                                                ...   \n",
       "1485        857  double eviction big brother model caprice holb...   \n",
       "1486        325  dj double act revamp chart show dj duo jk joel...   \n",
       "1487       1590  weak dollar hit reuters revenue medium group r...   \n",
       "1488       1587  apple ipod family expands market apple expande...   \n",
       "1489        538  santy worm make unwelcome visit thousand websi...   \n",
       "\n",
       "           Category  \n",
       "0          business  \n",
       "1          business  \n",
       "2          business  \n",
       "3              tech  \n",
       "4          business  \n",
       "...             ...  \n",
       "1485  entertainment  \n",
       "1486  entertainment  \n",
       "1487       business  \n",
       "1488           tech  \n",
       "1489           tech  \n",
       "\n",
       "[1440 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75f880e-040a-4821-abca-319bf3f5371d",
   "metadata": {},
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce25c332-0c20-438f-81e5-dc43c1a35319",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = train_df['processed_text']\n",
    "\n",
    "# Initialize TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "\n",
    "# Fit and transform the text data\n",
    "dtm = vectorizer.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3159887d-131b-4374-bc2a-4fa315243155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the sparse matrix to a dense format (only for inspection, as this can be memory-intensive)\n",
    "dtm_dense = dtm.toarray()\n",
    "\n",
    "# Get the feature names (terms)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Create a DataFrame for easier inspection\n",
    "dtm_df = pd.DataFrame(dtm_dense, columns=feature_names)\n",
    "\n",
    "# Display the first few rows of the matrix\n",
    "dtm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4873ce-5c04-4730-a60f-6ac86abbdc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Sum the frequencies of each term across all documents\n",
    "word_frequencies = np.sum(dtm.toarray(), axis=0)\n",
    "\n",
    "# Create a DataFrame for the word frequencies\n",
    "freq_df = pd.DataFrame({'Term': feature_names, 'Frequency': word_frequencies})\n",
    "\n",
    "# Sort the DataFrame by frequency\n",
    "freq_df = freq_df.sort_values(by='Frequency', ascending=False)\n",
    "\n",
    "# Display the top 10 most frequent words\n",
    "freq_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b779ad6d-2ebf-459d-ba0a-7bb3fcef5e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the top 20 most frequent words\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x='Frequency', y='Term', data=freq_df.head(20))\n",
    "plt.title('Top 20 Most Frequent Words')\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Words')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142437c1-b863-4b0b-9ddb-6334f89c4fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# Initialize the NMF model\n",
    "num_topics = 5  # Choose the number of topics\n",
    "nmf_model = NMF(n_components=num_topics, random_state=42)\n",
    "\n",
    "# Fit the model to the document-term matrix\n",
    "W = nmf_model.fit_transform(dtm)\n",
    "H = nmf_model.components_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96bbc2d-8e41-4428-b0b6-1015c494bcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature names (terms)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Print top terms for each topic\n",
    "num_top_words = 10  # Number of top words to display for each topic\n",
    "for topic_idx, topic in enumerate(H):\n",
    "    top_terms_idx = topic.argsort()[-num_top_words:][::-1]\n",
    "    top_terms = [feature_names[i] for i in top_terms_idx]\n",
    "    print(f\"Topic {topic_idx}:\")\n",
    "    print(\" \".join(top_terms))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722ff40e-4b29-4029-a31c-7ba107e27427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the topic with the highest score to each document\n",
    "train_df['Topic'] = W.argmax(axis=1)\n",
    "\n",
    "# Display the first few rows with assigned topics\n",
    "train_df[['ArticleId', 'Category', 'Topic']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e4e5e4-5d16-4bfa-bfb2-4531d4329941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of topics across documents\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Topic', data=train_df)\n",
    "plt.title('Distribution of Topics Across Documents')\n",
    "plt.xlabel('Topic')\n",
    "plt.ylabel('Number of Documents')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893cb26f-a701-4995-b04b-4939be543af1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3494c7c5-cadf-42e7-843a-bb1e41e76a49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c0d533-e5c5-44ca-b787-9ca80094395f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac1f8b9-a373-4e0a-947a-0708caa75f18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd8e82e-c08d-4888-920b-facef03b4ab6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1517399b-78f2-4726-a9c4-4f2479391094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c681fd18-6535-4b70-9943-e9766573f5a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64af71c-0a74-446f-b476-d18f0ae2577a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "581c331e-7a05-4b39-bc09-7ac128a909df",
   "metadata": {},
   "source": [
    "## References:\n",
    "\n",
    "1. **ChatGPT.** Damn rights, I used it and not going to pretend I didn't! I already knew the structure of pipelines and preprocessors from previous ML classes (both at UC Boulder and elsewhere). I had written out code for the tokenization and thought - why don't I incorporate this into a pipeline? That's when I turned to AI for assistance. There was a lot of back and forth, because nothing ever worked the first (or 5th) time around. AI is a tool, not a crutch. I suppose a crutch _IS_ a tool, but I digress.  **TLDR; I used AI for assistance, NOT to do the work for me.**    \n",
    "      \n",
    "2. All course lectures, notebooks, examples, readings, and material etc. were heavily referenced throughout this entire notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79708a5a-3c36-4cba-91aa-882463cd29fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
