{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22cf2177-3108-44ca-8960-ba364798712c",
   "metadata": {},
   "source": [
    "# Week 4: BBC News Classification Project\n",
    "## DTSA 5510 - Intro to Machine Learning - Unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c1d3469-036b-4067-993e-49ae664e1a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74ee3b9a-5b3b-4c62-838c-0395b7539531",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bergs\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\bergs\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\bergs\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\bergs\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d623ee-694b-4d35-95d4-74cca6875478",
   "metadata": {},
   "source": [
    "### EDA & cleaning\n",
    "\n",
    "The first step in any project is conducting some exploratory data analysis and cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5e4a57-b545-4ef7-bc46-5be6f8f5f19c",
   "metadata": {},
   "source": [
    "EDA\n",
    "* check for duplicate text\n",
    "* check for missing text\n",
    "* histogram of articles by category\n",
    "  \n",
    "Make pipleline to preprocess data\n",
    "* remove missing text\n",
    "* remove duplicate text\n",
    "* tokenize text\n",
    "* tfidf_vectorizer, plot scores\n",
    "\n",
    "Make pipeline to Modeling\n",
    "* non-negative matrix factorization models\n",
    "    * Frobenius Loss\n",
    "    * Kullback-Leibler Divergence \n",
    "    * plot top words per topic\n",
    "* Compare to supervised learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d00fdcf9-4c36-4b5e-89ad-2be5ac56a59a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1833</td>\n",
       "      <td>worldcom ex-boss launches defence lawyers defe...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154</td>\n",
       "      <td>german business confidence slides german busin...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1101</td>\n",
       "      <td>bbc poll indicates economic gloom citizens in ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1976</td>\n",
       "      <td>lifestyle  governs mobile choice  faster  bett...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>917</td>\n",
       "      <td>enron bosses in $168m payout eighteen former e...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ArticleId                                               Text  Category\n",
       "0       1833  worldcom ex-boss launches defence lawyers defe...  business\n",
       "1        154  german business confidence slides german busin...  business\n",
       "2       1101  bbc poll indicates economic gloom citizens in ...  business\n",
       "3       1976  lifestyle  governs mobile choice  faster  bett...      tech\n",
       "4        917  enron bosses in $168m payout eighteen former e...  business"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data\n",
    "train_df = pd.read_csv('data/BBC News Train.csv')\n",
    "\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c463c00d-8e4a-4085-81da-7f62998edfe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1490 entries, 0 to 1489\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   ArticleId  1490 non-null   int64 \n",
      " 1   Text       1490 non-null   object\n",
      " 2   Category   1490 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 35.1+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0a8271-da50-4508-a53a-3529aadddca2",
   "metadata": {},
   "source": [
    "To visualize the occurence of each word in the articles, I'll first tokenize the text column (split the text into individual words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a23cdbcc-3a32-43f5-bc8a-8d8e1b4a617e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1833</td>\n",
       "      <td>worldcom ex-boss launches defence lawyers defe...</td>\n",
       "      <td>business</td>\n",
       "      <td>[worldcom, ex-boss, launches, defence, lawyers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154</td>\n",
       "      <td>german business confidence slides german busin...</td>\n",
       "      <td>business</td>\n",
       "      <td>[german, business, confidence, slides, german,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1101</td>\n",
       "      <td>bbc poll indicates economic gloom citizens in ...</td>\n",
       "      <td>business</td>\n",
       "      <td>[bbc, poll, indicates, economic, gloom, citize...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ArticleId                                               Text  Category  \\\n",
       "0       1833  worldcom ex-boss launches defence lawyers defe...  business   \n",
       "1        154  german business confidence slides german busin...  business   \n",
       "2       1101  bbc poll indicates economic gloom citizens in ...  business   \n",
       "\n",
       "                                              tokens  \n",
       "0  [worldcom, ex-boss, launches, defence, lawyers...  \n",
       "1  [german, business, confidence, slides, german,...  \n",
       "2  [bbc, poll, indicates, economic, gloom, citize...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize text column\n",
    "train_df['tokens'] = train_df['Text'].apply(nltk.word_tokenize)\n",
    "\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffc1bf0-99b3-4c33-bf4e-9ff6a069f2c4",
   "metadata": {},
   "source": [
    "Next I'll remove the stop words like 'the', 'is', 'and' and so on. Stop words don't hold much significance in topic modelling and are unnecessary. None of the token words contain upper-case characters, so removal of those is unnecessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "544c4c06-5602-4733-8121-94e1ac7a1417",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bergs\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>tokens</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1833</td>\n",
       "      <td>worldcom ex-boss launches defence lawyers defe...</td>\n",
       "      <td>business</td>\n",
       "      <td>[worldcom, launch, defence, lawyer, defending,...</td>\n",
       "      <td>worldcom launch defence lawyer defending forme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154</td>\n",
       "      <td>german business confidence slides german busin...</td>\n",
       "      <td>business</td>\n",
       "      <td>[german, business, confidence, slide, german, ...</td>\n",
       "      <td>german business confidence slide german busine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1101</td>\n",
       "      <td>bbc poll indicates economic gloom citizens in ...</td>\n",
       "      <td>business</td>\n",
       "      <td>[bbc, poll, indicates, economic, gloom, citize...</td>\n",
       "      <td>bbc poll indicates economic gloom citizen majo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ArticleId                                               Text  Category  \\\n",
       "0       1833  worldcom ex-boss launches defence lawyers defe...  business   \n",
       "1        154  german business confidence slides german busin...  business   \n",
       "2       1101  bbc poll indicates economic gloom citizens in ...  business   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [worldcom, launch, defence, lawyer, defending,...   \n",
       "1  [german, business, confidence, slide, german, ...   \n",
       "2  [bbc, poll, indicates, economic, gloom, citize...   \n",
       "\n",
       "                                      processed_text  \n",
       "0  worldcom launch defence lawyer defending forme...  \n",
       "1  german business confidence slide german busine...  \n",
       "2  bbc poll indicates economic gloom citizen majo...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "# stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "train_df['tokens'] = train_df['tokens'].apply(lambda x: [word for word in x if word.lower() not in stop_words])\n",
    "\n",
    "# lowercase only\n",
    "train_df['tokens'] = train_df['tokens'].apply(lambda x: [word.lower() for word in x])\n",
    "\n",
    "# lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "train_df['tokens'] = train_df['tokens'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "\n",
    "# Remove Punctuation\n",
    "train_df['tokens'] = train_df['tokens'].apply(lambda x: [word for word in x if word.isalpha()])\n",
    "\n",
    "# Join Tokens\n",
    "train_df['processed_text'] = train_df['tokens'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Display the preprocessed text\n",
    "train_df[['ArticleId', 'processed_text', 'Category']].head()\n",
    "\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75f880e-040a-4821-abca-319bf3f5371d",
   "metadata": {},
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce25c332-0c20-438f-81e5-dc43c1a35319",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = train_df['processed_text']\n",
    "\n",
    "# Initialize TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "\n",
    "# Fit and transform the text data\n",
    "dtm = vectorizer.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3159887d-131b-4374-bc2a-4fa315243155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the sparse matrix to a dense format (only for inspection, as this can be memory-intensive)\n",
    "dtm_dense = dtm.toarray()\n",
    "\n",
    "# Get the feature names (terms)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Create a DataFrame for easier inspection\n",
    "dtm_df = pd.DataFrame(dtm_dense, columns=feature_names)\n",
    "\n",
    "# Display the first few rows of the matrix\n",
    "dtm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4873ce-5c04-4730-a60f-6ac86abbdc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Sum the frequencies of each term across all documents\n",
    "word_frequencies = np.sum(dtm.toarray(), axis=0)\n",
    "\n",
    "# Create a DataFrame for the word frequencies\n",
    "freq_df = pd.DataFrame({'Term': feature_names, 'Frequency': word_frequencies})\n",
    "\n",
    "# Sort the DataFrame by frequency\n",
    "freq_df = freq_df.sort_values(by='Frequency', ascending=False)\n",
    "\n",
    "# Display the top 10 most frequent words\n",
    "freq_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b779ad6d-2ebf-459d-ba0a-7bb3fcef5e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the top 20 most frequent words\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x='Frequency', y='Term', data=freq_df.head(20))\n",
    "plt.title('Top 20 Most Frequent Words')\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Words')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142437c1-b863-4b0b-9ddb-6334f89c4fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# Initialize the NMF model\n",
    "num_topics = 5  # Choose the number of topics\n",
    "nmf_model = NMF(n_components=num_topics, random_state=42)\n",
    "\n",
    "# Fit the model to the document-term matrix\n",
    "W = nmf_model.fit_transform(dtm)\n",
    "H = nmf_model.components_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96bbc2d-8e41-4428-b0b6-1015c494bcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature names (terms)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Print top terms for each topic\n",
    "num_top_words = 10  # Number of top words to display for each topic\n",
    "for topic_idx, topic in enumerate(H):\n",
    "    top_terms_idx = topic.argsort()[-num_top_words:][::-1]\n",
    "    top_terms = [feature_names[i] for i in top_terms_idx]\n",
    "    print(f\"Topic {topic_idx}:\")\n",
    "    print(\" \".join(top_terms))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722ff40e-4b29-4029-a31c-7ba107e27427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the topic with the highest score to each document\n",
    "train_df['Topic'] = W.argmax(axis=1)\n",
    "\n",
    "# Display the first few rows with assigned topics\n",
    "train_df[['ArticleId', 'Category', 'Topic']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e4e5e4-5d16-4bfa-bfb2-4531d4329941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of topics across documents\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Topic', data=train_df)\n",
    "plt.title('Distribution of Topics Across Documents')\n",
    "plt.xlabel('Topic')\n",
    "plt.ylabel('Number of Documents')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893cb26f-a701-4995-b04b-4939be543af1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3494c7c5-cadf-42e7-843a-bb1e41e76a49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c0d533-e5c5-44ca-b787-9ca80094395f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac1f8b9-a373-4e0a-947a-0708caa75f18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd8e82e-c08d-4888-920b-facef03b4ab6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1517399b-78f2-4726-a9c4-4f2479391094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c681fd18-6535-4b70-9943-e9766573f5a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64af71c-0a74-446f-b476-d18f0ae2577a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07869f4-33df-4d80-9dd3-24a676af012f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
